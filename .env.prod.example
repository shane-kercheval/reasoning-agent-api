# Production Environment Configuration
# Copy this file to .env for production deployment

# =============================================================================
# LITELLM PROXY CONFIGURATION
# =============================================================================

# LiteLLM Master Key (for admin operations like creating virtual keys)
# Used by: scripts/setup_litellm_keys.sh, LiteLLM proxy admin API
LITELLM_MASTER_KEY=

# LiteLLM PostgreSQL Password
# Used by: postgres-litellm service, LiteLLM database connection
LITELLM_POSTGRES_PASSWORD=

# LiteLLM Virtual Keys (generated by setup script - LEAVE EMPTY initially)
# After running `make litellm_setup`, copy generated keys here

# LITELLM_API_KEY: Virtual key for production application code
# This is what your code uses to call LiteLLM
LITELLM_API_KEY=

# LITELLM_TEST_KEY: Virtual key for integration tests (separate usage tracking)
# Used by: integration tests to track test usage separately from production
LITELLM_TEST_KEY=

# LITELLM_EVAL_KEY: Virtual key for LLM evaluations (separate tracking)
# Used by: LLM behavioral evaluations with flex-evals
LITELLM_EVAL_KEY=

# =============================================================================
# SHARED CONFIGURATION
# =============================================================================

# OpenAI API Configuration
# OPENAI_API_KEY is ONLY used by LiteLLM proxy to call OpenAI
# Flow: reasoning-api → LITELLM_API_KEY → litellm proxy → OPENAI_API_KEY → OpenAI
# Required: Your REAL OpenAI API key (used ONLY by LiteLLM proxy)
OPENAI_API_KEY=your-openai-api-key-here

# Authentication - Production tokens (generate secure tokens)
# API_TOKENS: Comma-separated list of valid bearer tokens for API authentication
# Used by: api/auth.py for validating Authorization: Bearer <token> headers
# Generate secure tokens: uv run python -c "import secrets; print(secrets.token_urlsafe(32))"
# Default: "" (empty, no authentication)
API_TOKENS=web-client-prod-token,admin-prod-token,mobile-prod-token

# REASONING_API_TOKEN: Specific token used by web client to authenticate with API
# Used by: web-client/main.py in Authorization headers
# Must be one of the tokens listed in API_TOKENS above
# Default: "web-client-dev-token"
REASONING_API_TOKEN=web-client-prod-token

# REQUIRE_AUTH: Enable/disable bearer token authentication for API endpoints
# Used by: api/auth.py and api/config.py
# Set to false for development, true for production
# Default: true
REQUIRE_AUTH=true

# Production Settings
# DEBUG: Enable debug mode and verbose logging
# Used by: api/config.py for development features
# Default: false
DEBUG=false

# =============================================================================
# REASONING API SERVICE
# =============================================================================

# Server Configuration
# API_HOST: Host address for the API server to bind to
# Used by: api/config.py for uvicorn server startup
# Common values: 0.0.0.0 (all interfaces), 127.0.0.1 (localhost only)
# Default: "0.0.0.0"
API_HOST=0.0.0.0

# API_PORT: Port number for the API server
# Used by: api/config.py for uvicorn server startup
# Default: 8000
API_PORT=8000

# HTTP Client Timeouts (seconds)
# HTTP_CONNECT_TIMEOUT: Connection timeout for HTTP requests to OpenAI API
# Used by: api/dependencies.py in httpx client configuration
# Default: 5.0
HTTP_CONNECT_TIMEOUT=5.0

# HTTP_READ_TIMEOUT: Read timeout for HTTP responses from OpenAI API
# Used by: api/dependencies.py in httpx client configuration
# Increase for slower streaming responses
# Default: 30.0
HTTP_READ_TIMEOUT=60.0

# HTTP_WRITE_TIMEOUT: Write timeout for HTTP requests to OpenAI API
# Used by: api/dependencies.py in httpx client configuration
# Default: 10.0
HTTP_WRITE_TIMEOUT=10.0

# HTTP Connection Pooling
# HTTP_MAX_CONNECTIONS: Maximum total HTTP connections in the pool
# Used by: api/dependencies.py in httpx.Limits configuration
# Default: 20
HTTP_MAX_CONNECTIONS=20

# HTTP_MAX_KEEPALIVE_CONNECTIONS: Maximum keep-alive connections in pool
# Used by: api/dependencies.py in httpx.Limits configuration
# Default: 5
HTTP_MAX_KEEPALIVE_CONNECTIONS=5

# HTTP_KEEPALIVE_EXPIRY: Keep-alive connection expiry time in seconds
# Used by: api/dependencies.py in httpx.Limits configuration
# Default: 30.0
HTTP_KEEPALIVE_EXPIRY=30.0

# =============================================================================
# WEB CLIENT SERVICE
# =============================================================================

# Service Configuration
# WEB_CLIENT_PORT: Port for the web client FastHTML application
# Used by: web-client/main.py for uvicorn server startup
# Default: 8080
WEB_CLIENT_PORT=8080

# REASONING_API_URL: URL where web client connects to the reasoning API
# Used by: web-client/main.py for making HTTP requests to the API
# Docker: http://reasoning-api:8000 (internal networking)
# External: https://your-api.onrender.com (separate deployments)
# Default: "http://localhost:8000"
REASONING_API_URL=http://reasoning-api:8000  # Docker internal networking
# REASONING_API_URL=https://your-api.onrender.com  # External URL for separate deployments

# =============================================================================
# MCP SERVICE (Future)
# =============================================================================

# Service Configuration
# MCP_SERVER_PORT: Port for MCP (Model Context Protocol) server
# Used by: mcp_servers/fake_server.py and Docker configurations
# Default: 8001
MCP_SERVER_PORT=8001

# =============================================================================
# PHOENIX ARIZE CONFIGURATION
# =============================================================================

# PostgreSQL Configuration for Phoenix (required for Docker)
# PHOENIX_POSTGRES_PASSWORD: Password for PostgreSQL database used by Phoenix
# Used by: docker-compose.yml for Phoenix database authentication
# IMPORTANT: Generate a secure password for production!
# Generate secure password: uv run python -c "import secrets; print(secrets.token_urlsafe(32))"
PHOENIX_POSTGRES_PASSWORD=phoenix_dev_password123

# NOTE: Other Phoenix configuration is handled entirely in docker-compose.yml
# Phoenix only runs in Docker environments and all env vars are set there

# =============================================================================
# PRODUCTION DEPLOYMENT EXAMPLES
# =============================================================================

# Container Platform Example (Docker Compose):
# OPENAI_API_KEY=sk-proj-abc123...
# API_TOKENS=cN8mK2pQ7rShJ9vF,X4hB2nKdL5wT,M7yR3sZaE6cV
# REASONING_API_URL=http://reasoning-api:8000
# REASONING_API_TOKEN=cN8mK2pQ7rShJ9vF
# REQUIRE_AUTH=true

# Individual Service Deployment Example:
# OPENAI_API_KEY=sk-proj-abc123...
# API_TOKENS=cN8mK2pQ7rShJ9vF,X4hB2nKdL5wT,M7yR3sZaE6cV
# REASONING_API_URL=https://your-api.onrender.com
# REASONING_API_TOKEN=cN8mK2pQ7rShJ9vF
# REQUIRE_AUTH=true
