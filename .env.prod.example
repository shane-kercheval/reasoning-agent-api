# Production Environment Configuration
# Copy this file to .env for production deployment

# =============================================================================
# SHARED CONFIGURATION
# =============================================================================

# OpenAI API Configuration
# Required: Your OpenAI API key for making chat completion requests
# Get from: https://platform.openai.com/api-keys
# Format: sk-proj-... (project API key) or sk-... (user API key)
OPENAI_API_KEY=your-openai-api-key-here

# Authentication - Production tokens (generate secure tokens)
# API_TOKENS: Comma-separated list of valid bearer tokens for API authentication
# Used by: api/auth.py for validating Authorization: Bearer <token> headers
# Generate secure tokens: python -c "import secrets; print(secrets.token_urlsafe(32))"
# Default: "" (empty, no authentication)
API_TOKENS=web-client-prod-token,admin-prod-token,mobile-prod-token

# REASONING_API_TOKEN: Specific token used by web client to authenticate with API
# Used by: web-client/main.py in Authorization headers
# Must be one of the tokens listed in API_TOKENS above
# Default: "web-client-dev-token"
REASONING_API_TOKEN=web-client-prod-token

# REQUIRE_AUTH: Enable/disable bearer token authentication for API endpoints
# Used by: api/auth.py and api/config.py
# Set to false for development, true for production
# Default: true
REQUIRE_AUTH=true

# Production Settings
# DEBUG: Enable debug mode and verbose logging
# Used by: api/config.py for development features
# Default: false
DEBUG=false

# =============================================================================
# REASONING API SERVICE
# =============================================================================

# Server Configuration
# API_HOST: Host address for the API server to bind to
# Used by: api/config.py for uvicorn server startup
# Common values: 0.0.0.0 (all interfaces), 127.0.0.1 (localhost only)
# Default: "0.0.0.0"
API_HOST=0.0.0.0

# API_PORT: Port number for the API server
# Used by: api/config.py for uvicorn server startup
# Default: 8000
API_PORT=8000

# API URL for Reasoning Agent
# REASONING_AGENT_BASE_URL: Base URL for OpenAI API or compatible service
# Used by: api/dependencies.py in ReasoningAgent for making chat completion requests
# Common values: https://api.openai.com/v1 (OpenAI), custom proxy URLs
# Default: "https://api.openai.com/v1"
REASONING_AGENT_BASE_URL=https://api.openai.com/v1

# HTTP Client Timeouts (seconds)
# HTTP_CONNECT_TIMEOUT: Connection timeout for HTTP requests to OpenAI API
# Used by: api/dependencies.py in httpx client configuration
# Default: 5.0
HTTP_CONNECT_TIMEOUT=5.0

# HTTP_READ_TIMEOUT: Read timeout for HTTP responses from OpenAI API
# Used by: api/dependencies.py in httpx client configuration
# Increase for slower streaming responses
# Default: 30.0
HTTP_READ_TIMEOUT=60.0

# HTTP_WRITE_TIMEOUT: Write timeout for HTTP requests to OpenAI API
# Used by: api/dependencies.py in httpx client configuration
# Default: 10.0
HTTP_WRITE_TIMEOUT=10.0

# HTTP Connection Pooling
# HTTP_MAX_CONNECTIONS: Maximum total HTTP connections in the pool
# Used by: api/dependencies.py in httpx.Limits configuration
# Default: 20
HTTP_MAX_CONNECTIONS=20

# HTTP_MAX_KEEPALIVE_CONNECTIONS: Maximum keep-alive connections in pool
# Used by: api/dependencies.py in httpx.Limits configuration
# Default: 5
HTTP_MAX_KEEPALIVE_CONNECTIONS=5

# HTTP_KEEPALIVE_EXPIRY: Keep-alive connection expiry time in seconds
# Used by: api/dependencies.py in httpx.Limits configuration
# Default: 30.0
HTTP_KEEPALIVE_EXPIRY=30.0

# =============================================================================
# WEB CLIENT SERVICE
# =============================================================================

# Service Configuration
# WEB_CLIENT_PORT: Port for the web client FastHTML application
# Used by: web-client/main.py for uvicorn server startup
# Default: 8080
WEB_CLIENT_PORT=8080

# REASONING_API_URL: URL where web client connects to the reasoning API
# Used by: web-client/main.py for making HTTP requests to the API
# Docker: http://reasoning-api:8000 (internal networking)
# External: https://your-api.onrender.com (separate deployments)
# Default: "http://localhost:8000"
REASONING_API_URL=http://reasoning-api:8000  # Docker internal networking
# REASONING_API_URL=https://your-api.onrender.com  # External URL for separate deployments

# =============================================================================
# MCP SERVICE (Future)
# =============================================================================

# Service Configuration
# MCP_SERVER_PORT: Port for MCP (Model Context Protocol) server
# Used by: mcp_servers/fake_server.py and Docker configurations
# Default: 8001
MCP_SERVER_PORT=8001

# =============================================================================
# PHOENIX ARIZE CONFIGURATION
# =============================================================================

# PostgreSQL Configuration for Phoenix (required for Docker)
# POSTGRES_PASSWORD: Password for PostgreSQL database used by Phoenix
# Used by: docker-compose.yml for Phoenix database authentication
# IMPORTANT: Generate a secure password for production!
# Generate secure password: python -c "import secrets; print(secrets.token_urlsafe(32))"
POSTGRES_PASSWORD=phoenix_dev_password123

# NOTE: Other Phoenix configuration is handled entirely in docker-compose.yml
# Phoenix only runs in Docker environments and all env vars are set there

# =============================================================================
# PRODUCTION DEPLOYMENT EXAMPLES
# =============================================================================

# Container Platform Example (Docker Compose):
# OPENAI_API_KEY=sk-proj-abc123...
# API_TOKENS=cN8mK2pQ7rShJ9vF,X4hB2nKdL5wT,M7yR3sZaE6cV
# REASONING_API_URL=http://reasoning-api:8000
# REASONING_API_TOKEN=cN8mK2pQ7rShJ9vF
# REQUIRE_AUTH=true

# Individual Service Deployment Example:
# OPENAI_API_KEY=sk-proj-abc123...
# API_TOKENS=cN8mK2pQ7rShJ9vF,X4hB2nKdL5wT,M7yR3sZaE6cV
# REASONING_API_URL=https://your-api.onrender.com
# REASONING_API_TOKEN=cN8mK2pQ7rShJ9vF
# REQUIRE_AUTH=true

# =============================================================================
# DEPLOYMENT WORKFLOW
# =============================================================================

# 1. Copy this file: cp .env.prod.example .env
# 2. Generate secure tokens (see command above)
# 3. Set real OpenAI API key
# 4. Configure REASONING_API_URL for your deployment
# 5. Deploy to your container platform
# 5. Access web interface: http://localhost:8080
# 6. Access API docs: http://localhost:8000/docs
# 7. Access Phoenix UI: http://localhost:6006
