# Implementation Plan: File-Based Prompt System

## Overview

Add support for defining prompts as Markdown files with YAML frontmatter, loaded from a configurable external directory. This enables prompts to be managed in a separate Git repository and edited without code changes.

**Key Design Decisions:**
- Format: Markdown files with YAML frontmatter (one file per prompt)
- Template engine: Jinja2 for variable substitution
- Location: Configurable directory via environment variable
- Class hierarchy: `BasePrompt` (ABC) → `PromptTemplate` (concrete, Jinja2-based)
- Coexistence: File-based (`PromptTemplate`) and code-based (`BasePrompt` subclasses) prompts both register in `PromptRegistry`

**Architecture:**
- `BasePrompt` - Abstract base class, kept for future complex prompt types
- `PromptTemplate(BasePrompt)` - Concrete class for Jinja2 template-based prompts
- `PromptInfo` (renamed from `PromptDefinition`) - API response model for listing prompts
- `PromptResult` - Changed to return `content: str` instead of `messages: list`
- Parser function returns `PromptTemplate` instances directly (no intermediate dataclass)

---

## Milestone 0: Add Category Field to Tools and Prompts

### Goal
Add a `category: str` field to both tools and prompts for better organization.

### Success Criteria
- `ToolDefinition` model has `category: str` field
- `BaseTool` has `category` property (with default empty string)
- All existing tool classes updated with appropriate categories
- `PromptDefinition` model has `category: str` field (will be renamed to `PromptInfo` in M1)
- `BasePrompt` has `category` property (with default empty string)
- `GreetingPrompt` example updated with category
- API responses include category in tool/prompt listings
- Existing tests updated, new tests for category field

### Key Changes

**Update: `tools_api/tools_api/models.py`**

```python
class ToolDefinition(BaseModel):
    name: str = Field(description="Tool name (used in API endpoint)")
    description: str = Field(description="Human-readable description")
    parameters: dict[str, Any] = Field(description="JSON Schema for parameters")
    category: str | None = Field(default=None, description="Tool category for organization")
    tags: list[str] = Field(default_factory=list, description="Semantic tags")

class PromptDefinition(BaseModel):
    name: str = Field(description="Prompt name (used in API endpoint)")
    description: str = Field(description="Human-readable description")
    arguments: list[dict[str, Any]] = Field(...)
    category: str | None = Field(default=None, description="Prompt category for organization")
    tags: list[str] = Field(default_factory=list, description="Semantic tags")
```

**Update: `tools_api/tools_api/services/base.py`**

Add to both `BaseTool` and `BasePrompt`:

```python
@property
def category(self) -> str | None:
    """Category for organization. Override in subclasses."""
    return None
```

**Update: All existing tool classes**

Add `category` property to each tool class:
- Filesystem tools: `category = "filesystem"`
- GitHub/dev tools: `category = "github"`
- Web tools: `category = "web"`

**Update: `tools_api/tools_api/routers/tools.py` and `prompts.py`**

Include `category` in the list endpoint responses.

### Testing Strategy

- Verify `category` appears in `GET /tools/` response
- Verify `category` appears in `GET /prompts/` response
- Test default empty category for tools/prompts that don't override
- Test category value for tools that do override

### Dependencies
None - this is foundational.

### Risk Factors
- Many files to update (all tool classes)
- Ensure no regressions in existing tests

---

## Milestone 1: Model Updates and Renames

### Goal
Update Pydantic models: rename `PromptDefinition` to `PromptInfo`, change `PromptResult` to return `content: str` instead of `messages: list`, and update `BasePrompt.render()` signature.

### Success Criteria
- `PromptDefinition` renamed to `PromptInfo` throughout codebase
- `PromptResult.messages` replaced with `PromptResult.content: str`
- `BasePrompt.render()` returns `str` instead of `list[dict[str, str]]`
- `GreetingPrompt` updated to return string
- All imports and usages updated
- Tests updated to reflect new return types

### Key Changes

**Update: `tools_api/tools_api/models.py`**

```python
class PromptResult(BaseModel):
    """Structured prompt rendering result."""
    success: bool = Field(description="Whether rendering was successful")
    content: str = Field(description="Rendered prompt content")
    error: str | None = Field(default=None, description="Error message if rendering failed")
    metadata: dict[str, Any] = Field(default_factory=dict, description="Additional metadata")

class PromptInfo(BaseModel):  # Renamed from PromptDefinition
    """Prompt metadata for discovery."""
    name: str = Field(description="Prompt name (used in API endpoint)")
    description: str = Field(description="Human-readable description")
    arguments: list[dict[str, Any]] = Field(...)
    category: str | None = Field(default=None, description="Prompt category")
    tags: list[str] = Field(default_factory=list, description="Semantic tags")
```

**Update: `tools_api/tools_api/services/base.py`**

```python
class BasePrompt(ABC):
    @abstractmethod
    async def render(self, **kwargs) -> str:
        """Render prompt and return content string."""
        pass

    async def __call__(self, **kwargs) -> PromptResult:
        try:
            content = await self.render(**kwargs)
            return PromptResult(success=True, content=content)
        except Exception as e:
            return PromptResult(success=False, content="", error=str(e))
```

**Update: `tools_api/tools_api/services/prompts/example_prompt.py`**

Update `GreetingPrompt.render()` to return `str`:

```python
async def render(self, name: str, formal: bool = False, **kwargs) -> str:
    if formal:
        return f"Good day, {name}. How may I assist you today?"
    else:
        return f"Hey {name}! What can I help you with?"
```

**Update: `tools_api/tools_api/routers/prompts.py`**

Update import from `PromptDefinition` to `PromptInfo`.

### Testing Strategy

- All existing prompt tests updated for new return type
- Verify `POST /prompts/{name}` returns `{"success": true, "content": "...", ...}`
- Verify `GET /prompts/` returns `PromptInfo` objects

### Dependencies
- Milestone 0 (category field)

### Risk Factors
- Breaking change to API response format
- Need to update all tests that check `messages` field

---

## Milestone 2: PromptTemplate Class

### Goal
Create `PromptTemplate` class that extends `BasePrompt` and handles Jinja2 template rendering.

### Success Criteria
- `PromptTemplate` implements all `BasePrompt` abstract methods
- Constructor accepts individual fields: `name`, `description`, `arguments`, `tags`, `category`, `template`
- Jinja2 rendering works with variable substitution and conditionals
- Missing required arguments raise clear errors
- Optional arguments render as empty string if not provided
- `PromptTemplate` instances work identically to code-based prompts in registry

### Key Changes

**New file: `tools_api/tools_api/services/prompts/template.py`**

Install Jinja2: `uv add jinja2`

Documentation: https://jinja.palletsprojects.com/en/3.1.x/

```python
from jinja2 import Template, UndefinedError

class PromptTemplate(BasePrompt):
    """Prompt implementation using Jinja2 templates."""

    def __init__(
        self,
        name: str,
        description: str,
        template: str,
        arguments: list[dict[str, Any]] | None = None,
        category: str | None = None,
        tags: list[str] | None = None,
    ):
        self._name = name
        self._description = description
        self._template_str = template
        self._template = Template(template)
        self._arguments = arguments or []
        self._category = category
        self._tags = tags or []

    @property
    def name(self) -> str:
        return self._name

    @property
    def description(self) -> str:
        return self._description

    @property
    def arguments(self) -> list[dict[str, Any]]:
        return self._arguments

    @property
    def category(self) -> str | None:
        return self._category

    @property
    def tags(self) -> list[str]:
        return self._tags

    async def render(self, **kwargs) -> str:
        """Render template with provided arguments."""
        # Validate required arguments are present
        for arg in self._arguments:
            if arg.get("required", False) and arg["name"] not in kwargs:
                raise ValueError(f"Missing required argument: {arg['name']}")

        # Render with Jinja2 (undefined variables become empty string)
        return self._template.render(**kwargs)
```

**Jinja2 configuration notes:**
- Use default `Undefined` behavior (undefined variables render as empty string)
- Required argument validation happens before rendering
- Template syntax errors surface at render time with clear messages

### Testing Strategy

**File: `tools_api/tests/unit_tests/test_prompt_template.py`**

- Basic variable substitution `{{ name }}`
- Conditional blocks `{% if focus %}...{% endif %}`
- Missing required argument raises `ValueError` with argument name
- Optional argument omitted renders as empty string
- Optional argument provided works correctly
- All properties return correct values
- `__call__` wrapper returns `PromptResult` with correct structure
- Empty template renders to empty string
- Template with no variables renders as-is
- Unicode content in template and arguments

### Dependencies
- Milestone 1 (model updates, `render()` returns `str`)

### Risk Factors
- Jinja2 undefined variable behavior - using lenient mode (empty string)
- Template syntax errors at render time

---

## Milestone 3: Parser and Loader

### Goal
Create parser function that reads Markdown files with YAML frontmatter and returns `PromptTemplate` instances. Create loader that scans directories recursively and registers prompts.

### Success Criteria
- Parser extracts frontmatter fields: `name`, `description`, `arguments`, `tags`, `category`
- Parser extracts markdown body as template content
- Parser returns `PromptTemplate` instance directly
- Parser validates required fields and raises clear errors
- Loader scans directory recursively for `*.md` files
- Invalid files log warnings but don't crash
- Non-existent directory raises `FileNotFoundError`
- Empty/missing directory config logs info and continues
- Duplicate prompt names raise errors

### Key Changes

**New file: `tools_api/tools_api/services/prompts/parser.py`**

Install: `uv add python-frontmatter`

Documentation: https://python-frontmatter.readthedocs.io/en/latest/

```python
import frontmatter
from pathlib import Path
from tools_api.services.prompts.template import PromptTemplate

def parse_prompt_file(file_path: Path) -> PromptTemplate:
    """
    Parse a markdown file with YAML frontmatter into a PromptTemplate.

    Required frontmatter fields: name, description
    Optional frontmatter fields: arguments, tags, category

    Args:
        file_path: Path to the markdown file

    Returns:
        PromptTemplate instance

    Raises:
        ValueError: If required fields are missing or file is malformed
    """
    post = frontmatter.load(file_path)

    # Validate required fields
    if "name" not in post.metadata:
        raise ValueError(f"Missing required field 'name' in {file_path}")
    if "description" not in post.metadata:
        raise ValueError(f"Missing required field 'description' in {file_path}")

    return PromptTemplate(
        name=post.metadata["name"],
        description=post.metadata["description"],
        template=post.content,
        arguments=post.metadata.get("arguments", []),
        category=post.metadata.get("category"),  # None if not specified
        tags=post.metadata.get("tags", []),
    )
```

**New file: `tools_api/tools_api/services/prompts/loader.py`**

```python
import logging
from pathlib import Path
from tools_api.services.prompts.parser import parse_prompt_file
from tools_api.services.prompts.template import PromptTemplate
from tools_api.services.registry import PromptRegistry

logger = logging.getLogger(__name__)

def load_prompts_from_directory(directory: Path) -> list[PromptTemplate]:
    """
    Scan directory recursively for .md files and return PromptTemplate instances.

    Logs warnings for invalid files but continues loading others.

    Args:
        directory: Path to prompts directory

    Returns:
        List of successfully parsed PromptTemplate instances

    Raises:
        FileNotFoundError: If directory does not exist
    """
    if not directory.exists():
        raise FileNotFoundError(f"Prompts directory not found: {directory}")

    prompts = []
    for file_path in directory.rglob("*.md"):
        try:
            prompt = parse_prompt_file(file_path)
            prompts.append(prompt)
            logger.info(f"Loaded prompt '{prompt.name}' from {file_path}")
        except Exception as e:
            logger.warning(f"Failed to load prompt from {file_path}: {e}")

    return prompts

def register_prompts_from_directory(directory: Path) -> int:
    """
    Load prompts from directory and register in PromptRegistry.

    Args:
        directory: Path to prompts directory

    Returns:
        Count of successfully registered prompts

    Raises:
        FileNotFoundError: If directory does not exist
        ValueError: On duplicate prompt names
    """
    prompts = load_prompts_from_directory(directory)
    for prompt in prompts:
        PromptRegistry.register(prompt)  # Raises ValueError on duplicate
    return len(prompts)
```

**Update: `tools_api/tools_api/config.py`**

```python
class Settings(BaseSettings):
    # ... existing fields

    # External prompts directory (optional)
    prompts_directory: Path | None = None
```

**Update: `tools_api/tools_api/main.py`**

In lifespan function, replace hardcoded `GreetingPrompt` registration:

```python
# Register file-based prompts from directory
if settings.prompts_directory:
    try:
        count = register_prompts_from_directory(settings.prompts_directory)
        logger.info(f"Registered {count} prompts from {settings.prompts_directory}")
    except FileNotFoundError as e:
        logger.error(f"Prompts directory not found: {e}")
        raise  # Fail startup if configured directory doesn't exist
else:
    logger.info("No prompts directory configured, skipping file-based prompts")

# Note: GreetingPrompt is kept as example code but NOT registered
# See tools_api/services/prompts/example_prompt.py for code-based prompt example
```

**Expected file format:**

```markdown
---
name: code_review
description: Review code for quality and best practices
category: development
arguments:
  - name: language
    required: true
    description: Programming language of the code
  - name: focus
    required: false
    description: Specific areas to focus on
tags:
  - code
  - review
---
You are a senior {{ language }} developer performing a code review.

{% if focus %}
Focus specifically on: {{ focus }}
{% endif %}

Review the code for quality, bugs, and best practices.
```

### Testing Strategy

**File: `tools_api/tests/unit_tests/test_prompt_parser.py`**

Use `tmp_path` fixture to create test files.

- Valid file with all fields populated
- Valid file with optional fields omitted
- Missing required field (`name`) raises `ValueError`
- Missing required field (`description`) raises `ValueError`
- Malformed YAML raises error
- Empty template body (valid)
- File with no frontmatter raises error
- Unicode content works

**File: `tools_api/tests/unit_tests/test_prompt_loader.py`**

- Directory with multiple valid `.md` files loads all
- Nested subdirectories are scanned (recursive)
- Non-`.md` files are ignored
- Invalid file logs warning and continues
- Empty directory returns empty list
- Non-existent directory raises `FileNotFoundError`
- Duplicate names across files raises `ValueError` during registration

### Dependencies
- Milestone 2 (`PromptTemplate` class)

### Risk Factors
- `python-frontmatter` library edge cases
- File permission errors in Docker

---

## Milestone 4: Integration Testing and Examples

### Goal
End-to-end validation that file-based prompts work through the API. Create example prompt files for reference.

### Success Criteria
- Integration test: prompts loaded from directory appear in `GET /prompts/`
- Integration test: prompts render correctly via `POST /prompts/{name}`
- Integration test: error handling for missing prompts, bad arguments
- Example prompt files demonstrate various features
- `GreetingPrompt` kept as code example but not registered

### Key Changes

**Update: `tools_api/tests/integration_tests/test_tools_api_http.py`**

Add tests using a test prompts directory (via `tmp_path` or test fixtures):

```python
# Test that file-based prompts appear in listing
# Test rendering with required arguments
# Test rendering with optional arguments
# Test error on missing required argument
# Test 404 on non-existent prompt
```

**New: `tools_api/examples/prompts/`**

Create example prompt files:

1. `greeting.md` - Simple variable substitution
2. `code_review.md` - Conditionals and multiple arguments
3. `summarize.md` - Minimal example (required fields only)

**Update: `tools_api/README.md`**

Add section documenting:
- Prompt file format (frontmatter fields, template syntax)
- Jinja2 features supported (`{{ var }}`, `{% if %}`, `{% for %}`)
- Configuration via `PROMPTS_DIRECTORY` environment variable
- Category and tags usage
- Examples

**Update: `tools_api/tools_api/services/prompts/example_prompt.py`**

Add comment explaining this is an example of a code-based prompt for complex use cases, but is not registered by default.

### Testing Strategy

Integration tests focus on full API flow:
- Start API with `PROMPTS_DIRECTORY` pointing to test fixtures
- Verify prompts appear in listing with correct metadata
- Verify rendering works with various argument combinations
- Verify error responses are properly formatted

### Dependencies
- Milestones 0-3

### Risk Factors
- Integration test setup complexity (injecting env var)
- Ensuring test prompts directory is available during CI

---

## Summary of Changes by File

| File | Changes |
|------|---------|
| `models.py` | Add `category` to `ToolDefinition`, rename `PromptDefinition` → `PromptInfo`, change `PromptResult.messages` → `content` |
| `base.py` | Add `category` property to `BaseTool` and `BasePrompt`, change `render()` return type to `str` |
| `registry.py` | No changes |
| `routers/prompts.py` | Update import to `PromptInfo` |
| `routers/tools.py` | Include `category` in response |
| `config.py` | Add `prompts_directory: Path \| None` |
| `main.py` | Replace hardcoded prompt registration with loader |
| `services/prompts/template.py` | New - `PromptTemplate` class |
| `services/prompts/parser.py` | New - `parse_prompt_file()` function |
| `services/prompts/loader.py` | New - `load_prompts_from_directory()`, `register_prompts_from_directory()` |
| `services/prompts/example_prompt.py` | Update `render()` return type, add comments |
| `services/tools/*.py` | Add `category` property to all tool classes |
| `examples/prompts/*.md` | New - example prompt files |
| `README.md` | Document prompt file format |

---

## Dependencies (Libraries)

| Library | Version | Purpose |
|---------|---------|---------|
| `jinja2` | latest | Template rendering |
| `python-frontmatter` | latest | YAML frontmatter parsing |

Install via: `uv add jinja2 python-frontmatter`
