# Development Environment Configuration
# Copy this file to .env for local development

# =============================================================================
# SHARED CONFIGURATION
# =============================================================================

# OpenAI API Configuration
# Required: Your OpenAI API key for making chat completion requests
# Get from: https://platform.openai.com/api-keys
# Format: sk-proj-... (project API key) or sk-... (user API key)
OPENAI_API_KEY=your-openai-api-key-here

# Authentication - Development tokens (easy to remember)
# API_TOKENS: Comma-separated list of valid bearer tokens for API authentication
# Used by: api/auth.py for validating Authorization: Bearer <token> headers
# Commented out for development (auth disabled)
# API_TOKENS=web-client-dev-token,admin-dev-token,mobile-dev-token

# REASONING_API_TOKEN: Specific token used by web client to authenticate with API
# Used by: web-client/main.py in Authorization headers
# Commented out for development (auth disabled)
# REASONING_API_TOKEN=web-client-dev-token

# REQUIRE_AUTH: Enable/disable bearer token authentication for API endpoints
# Used by: api/auth.py and api/config.py
# Set to false for easier development, true for production
# Default: true
REQUIRE_AUTH=false

# Development Settings
# DEBUG: Enable debug mode and verbose logging
# Used by: api/config.py for development features
# Default: false
DEBUG=true

# =============================================================================
# REASONING API SERVICE
# =============================================================================

# Server Configuration
# API_HOST: Host address for the API server to bind to
# Used by: api/config.py for uvicorn server startup
# Common values: 0.0.0.0 (all interfaces), 127.0.0.1 (localhost only)
# Default: "0.0.0.0"
API_HOST=0.0.0.0

# API_PORT: Port number for the API server
# Used by: api/config.py for uvicorn server startup
# Default: 8000
API_PORT=8000

# API URL for Reasoning Agent
# REASONING_AGENT_BASE_URL: Base URL for OpenAI API or compatible service
# Used by: api/dependencies.py in ReasoningAgent for making chat completion requests
# Common values: https://api.openai.com/v1 (OpenAI), custom proxy URLs
# Default: "https://api.openai.com/v1"
REASONING_AGENT_BASE_URL=https://api.openai.com/v1

# HTTP Client Timeouts (seconds)
# HTTP_CONNECT_TIMEOUT: Connection timeout for HTTP requests to OpenAI API
# Used by: api/dependencies.py in httpx client configuration
# Default: 5.0
HTTP_CONNECT_TIMEOUT=5.0

# HTTP_READ_TIMEOUT: Read timeout for HTTP responses from OpenAI API
# Used by: api/dependencies.py in httpx client configuration
# Increase for slower streaming responses
# Default: 30.0
HTTP_READ_TIMEOUT=60.0

# HTTP_WRITE_TIMEOUT: Write timeout for HTTP requests to OpenAI API
# Used by: api/dependencies.py in httpx client configuration
# Default: 10.0
HTTP_WRITE_TIMEOUT=10.0

# HTTP Connection Pooling
# HTTP_MAX_CONNECTIONS: Maximum total HTTP connections in the pool
# Used by: api/dependencies.py in httpx.Limits configuration
# Default: 20
HTTP_MAX_CONNECTIONS=20

# HTTP_MAX_KEEPALIVE_CONNECTIONS: Maximum keep-alive connections in pool
# Used by: api/dependencies.py in httpx.Limits configuration
# Default: 5
HTTP_MAX_KEEPALIVE_CONNECTIONS=5

# HTTP_KEEPALIVE_EXPIRY: Keep-alive connection expiry time in seconds
# Used by: api/dependencies.py in httpx.Limits configuration
# Default: 30.0
HTTP_KEEPALIVE_EXPIRY=30.0

# =============================================================================
# WEB CLIENT SERVICE
# =============================================================================

# Service Configuration
# WEB_CLIENT_PORT: Port for the web client FastHTML application
# Used by: web-client/main.py for uvicorn server startup
# Default: 8080
WEB_CLIENT_PORT=8080

# REASONING_API_URL: URL where web client connects to the reasoning API
# Used by: web-client/main.py for making HTTP requests to the API
# Development: http://localhost:8000 (local API server)
# Docker: http://reasoning-api:8000 (internal networking)
# Default: "http://localhost:8000"
REASONING_API_URL=http://localhost:8000  # Where web client connects to API

# =============================================================================
# MCP SERVICE (Future)
# =============================================================================

# Service Configuration
# MCP_SERVER_PORT: Port for MCP (Model Context Protocol) server
# Used by: mcp_servers/fake_server.py and Docker configurations
# Default: 8001
MCP_SERVER_PORT=8001

# =============================================================================
# PHOENIX ARIZE CONFIGURATION
# =============================================================================

# PostgreSQL Configuration for Phoenix (required for Docker)
# POSTGRES_PASSWORD: Password for PostgreSQL database used by Phoenix
# Used by: docker-compose.yml for Phoenix database authentication
# Generate secure password for production: python -c "import secrets; print(secrets.token_urlsafe(16))"
POSTGRES_PASSWORD=phoenix_dev_password123

# NOTE: Other Phoenix configuration is handled entirely in docker-compose.yml
# Phoenix only runs in Docker environments and all env vars are set there

# =============================================================================
# DEVELOPMENT WORKFLOW
# =============================================================================

# 1. Copy this file: cp .env.dev.example .env
# 2. Add your OpenAI API key above
# 3. For local development: make api && make web_client
# 4. For Docker development: make docker_up
# 5. Access web interface: http://localhost:8080
# 6. Access API docs: http://localhost:8000/docs
# 7. Access Phoenix UI: http://localhost:6006
