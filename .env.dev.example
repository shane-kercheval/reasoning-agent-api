# Development Environment Configuration
# Copy to .env and fill in your secrets
# All other settings use sensible defaults from api/config.py and docker-compose.yml

# =============================================================================
# REQUIRED SECRETS
# =============================================================================

# OpenAI API Key (required - used by LiteLLM proxy)
OPENAI_API_KEY=your-openai-api-key-here

# Anthropic API Key (optional - if using Claude models)
# ANTHROPIC_API_KEY=your-anthropic-key-here

# =============================================================================
# LITELLM CONFIGURATION
# =============================================================================

# Master Key for LiteLLM admin operations
# Generate: python -c "import secrets; print('sk-' + secrets.token_urlsafe(32))"
LITELLM_MASTER_KEY=

# Virtual Keys (generated by `make litellm_setup` - LEAVE EMPTY initially)
LITELLM_API_KEY=
LITELLM_TEST_KEY=
LITELLM_EVAL_KEY=

# Base URL (environment-specific)
# Local dev: http://localhost:4000
# Docker: http://litellm:4000 (set in docker-compose.yml)
# LITELLM_BASE_URL=http://localhost:4000

# =============================================================================
# DATABASE PASSWORDS
# =============================================================================

# Generate secure passwords: python -c "import secrets; print(secrets.token_urlsafe(16))"
LITELLM_POSTGRES_PASSWORD=
PHOENIX_POSTGRES_PASSWORD=
REASONING_POSTGRES_PASSWORD=

# Reasoning Database URL (environment-specific)
# Local: postgresql+asyncpg://reasoning_user:password@localhost:5434/reasoning
# Docker: postgresql+asyncpg://reasoning_user:password@postgres-reasoning:5432/reasoning
# REASONING_DATABASE_URL=postgresql+asyncpg://reasoning_user:${REASONING_POSTGRES_PASSWORD}@localhost:5434/reasoning

# =============================================================================
# DEVELOPMENT OVERRIDES
# =============================================================================

# Disable auth for easier local testing (default: true in production)
REQUIRE_AUTH=false

# Enable debug mode for verbose logging (default: false)
DEBUG=true

# =============================================================================
# OPTIONAL FEATURES
# =============================================================================

# MCP: Strip prefixes from tool/prompt names when using proxy servers
# Example: MCP_STRIP_PREFIXES=local_bridge_
# MCP_STRIP_PREFIXES=

# =============================================================================
# QUICK START
# =============================================================================
# 1. Copy this file: cp .env.dev.example .env
# 2. Add your OPENAI_API_KEY above
# 3. Generate passwords and run: make litellm_setup
# 4. Copy generated LITELLM_API_KEY, LITELLM_TEST_KEY, LITELLM_EVAL_KEY above
# 5. Run: make api (for local) or make docker_up (for Docker)
